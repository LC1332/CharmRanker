"""
Gemini æ‰¹é‡åˆ†ç±»è„šæœ¬

åŠŸèƒ½ï¼š
- ä½¿ç”¨å¹¶å‘è¯·æ±‚æ‰¹é‡å¤„ç†æ‰€æœ‰æœªåˆ†ç±»çš„æ•°æ®
- æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼ˆè·³è¿‡å·²å¤„ç†çš„å›¾ç‰‡ï¼‰
- æ˜¾ç¤ºè¿›åº¦æ¡
- è‡ªåŠ¨å¤„ç†é”™è¯¯å’Œé‡è¯•
"""

from __future__ import annotations

import json
import os
import sys
import time
import base64
import requests
from pathlib import Path
from typing import Set, Optional, Tuple
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è·¯å¾„é…ç½®
PROJECT_ROOT = Path(__file__).parent.parent.parent
LOCAL_DATA_DIR = PROJECT_ROOT / "local_data"

INPUT_JSONL = LOCAL_DATA_DIR / "crop_log_with_face_and_body.jsonl"
CROP_OUTPUT_DIR = LOCAL_DATA_DIR / "crop_output"
OUTPUT_JSONL = LOCAL_DATA_DIR / "crop_classify.jsonl"
FAILED_JSONL = LOCAL_DATA_DIR / "fail_to_classify.jsonl"

# API é…ç½®
LUMOS_API = os.getenv("LUMOS_API")
GEMINI_BASE_URL = os.getenv("GEMINI_BASE_URL", "")
GEMINI_MODEL = "gemini-3-flash-preview"

# å¹¶å‘é…ç½®
MAX_WORKERS = 10  # å¹¶å‘æ•°
BATCH_SIZE = 100  # æ¯æ‰¹å¤„ç†æ•°é‡ï¼Œç”¨äºå®šæœŸä¿å­˜è¿›åº¦
REQUEST_TIMEOUT = 120  # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

# åˆ†ç±» Prompt
CLASSIFICATION_PROMPT = """Based on the input image, analyze the person highlighted by the RED bounding box and determine their attributes.

Please output a JSON object with the following fields:

- "analysis": A brief analysis describing whether the red box clearly identifies a primary subject, whether the person appears to be Asian, their gender, and any other relevant observations.

- "gender": Output "male" for male, "female" for female. If it's a false detection or cannot be determined with confidence, output "unpredictable".

- "if_asian": Output "yes" if the person appears to be Asian (East Asian, Southeast Asian, etc.), output "no" if they appear to be non-Asian, output "uncertain" if it cannot be determined.

- "if_ambiguous": Whether the red bounding box clearly identifies exactly one person. Output "no" if the box primarily contains one person (even if other people partially appear at the edges). Output "yes" if the bounding box clearly contains two or more complete persons.

- "if_correct_face": Whether the GREEN face bounding box (if present) belongs to the person highlighted by the red box. Output "yes" if it matches, "no" if it doesn't match, "no_face_box" if there is no green face box visible.

- "if_frontal": Whether the person is facing the camera (frontal or side view where facial features are visible). Output "yes" if the face and facial features (eyes, nose, mouth) can be seen. Output "no" if the person is facing away or the face is not visible.

- "false_alarm": Whether the red box is a false detection (no person inside). Output "yes" if the red box does NOT contain any person (false alarm). Output "no" if there IS a person inside the red box.

Output ONLY the JSON object, no additional text or markdown formatting."""

# ç”¨äºçº¿ç¨‹å®‰å…¨çš„æ–‡ä»¶å†™å…¥
write_lock = Lock()


def load_processed_filenames() -> Set[str]:
    """åŠ è½½å·²å¤„ç†çš„æ–‡ä»¶åé›†åˆï¼ˆåŒ…æ‹¬æˆåŠŸå’Œå¤±è´¥çš„ï¼‰"""
    processed = set()
    
    # åŠ è½½æˆåŠŸçš„
    if OUTPUT_JSONL.exists():
        with open(OUTPUT_JSONL, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    record = json.loads(line)
                    if "output_filename" in record:
                        processed.add(record["output_filename"])
                except json.JSONDecodeError:
                    continue
    
    # åŠ è½½å¤±è´¥çš„ï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰
    if FAILED_JSONL.exists():
        with open(FAILED_JSONL, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    record = json.loads(line)
                    if "output_filename" in record:
                        processed.add(record["output_filename"])
                except json.JSONDecodeError:
                    continue
    
    return processed


def load_input_records() -> list:
    """åŠ è½½è¾“å…¥çš„ jsonl è®°å½•"""
    records = []
    
    if not INPUT_JSONL.exists():
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {INPUT_JSONL}")
        sys.exit(1)
    
    with open(INPUT_JSONL, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                record = json.loads(line)
                records.append(record)
            except json.JSONDecodeError:
                continue
    
    return records


def load_image_as_base64(image_path: Path) -> str:
    """åŠ è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸º base64"""
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")


def parse_json_response(text: str) -> dict:
    """è§£æ JSON å“åº”"""
    text = text.strip()
    if "```json" in text:
        text = text.split("```json")[1].split("```")[0]
    elif "```" in text:
        text = text.split("```")[1].split("```")[0]
    text = text.strip()
    return json.loads(text)


def append_to_jsonl(filepath: Path, record: dict):
    """çº¿ç¨‹å®‰å…¨åœ°è¿½åŠ è®°å½•åˆ° JSONL æ–‡ä»¶"""
    with write_lock:
        with open(filepath, "a", encoding="utf-8") as f:
            f.write(json.dumps(record, ensure_ascii=False) + "\n")


def classify_single_image(record: dict, max_retries: int = 2) -> Tuple[dict, Optional[dict], Optional[str]]:
    """
    åˆ†ç±»å•å¼ å›¾ç‰‡ï¼Œæ”¯æŒé‡è¯•
    
    Returns:
        (åŸå§‹è®°å½•, åˆ†ç±»ç»“æœ, é”™è¯¯ä¿¡æ¯)
    """
    output_filename = record["output_filename"]
    image_path = CROP_OUTPUT_DIR / output_filename
    
    if not image_path.exists():
        return record, None, f"å›¾ç‰‡ä¸å­˜åœ¨: {image_path}"
    
    last_error = None
    
    for attempt in range(max_retries + 1):
        try:
            # åŠ è½½å›¾ç‰‡
            image_base64 = load_image_as_base64(image_path)
            ext = image_path.suffix.lower()
            mime_type = "image/jpeg" if ext in [".jpg", ".jpeg"] else "image/png"
            
            # æ„å»ºè¯·æ±‚
            url = f"{GEMINI_BASE_URL}/v1/models/{GEMINI_MODEL}:generateContent"
            headers = {
                "Authorization": f"Bearer {LUMOS_API}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "contents": [{
                    "role": "user",
                    "parts": [
                        {"inline_data": {"mime_type": mime_type, "data": image_base64}},
                        {"text": CLASSIFICATION_PROMPT}
                    ]
                }],
                "generationConfig": {
                    "responseMimeType": "application/json"
                }
            }
            
            response = requests.post(url, headers=headers, json=payload, timeout=REQUEST_TIMEOUT)
            response.raise_for_status()
            
            result_data = response.json()
            result_text = result_data["candidates"][0]["content"]["parts"][0]["text"]
            classify_result = parse_json_response(result_text)
            
            return record, classify_result, None
            
        except Exception as e:
            last_error = str(e)
            if attempt < max_retries:
                time.sleep(1)  # çŸ­æš‚ç­‰å¾…åé‡è¯•
                continue
    
    return record, None, last_error


def run_batch_classify(pending_records: list, max_workers: int = MAX_WORKERS):
    """
    æ‰¹é‡å¹¶å‘åˆ†ç±»
    """
    total = len(pending_records)
    success_count = 0
    fail_count = 0
    
    print(f"\nğŸš€ å¼€å§‹æ‰¹é‡åˆ†ç±» (å¹¶å‘æ•°: {max_workers}, æ€»æ•°: {total})")
    print("=" * 60)
    
    start_time = time.time()
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        futures = {
            executor.submit(classify_single_image, record): i 
            for i, record in enumerate(pending_records)
        }
        
        # å¤„ç†å®Œæˆçš„ä»»åŠ¡
        for future in as_completed(futures):
            idx = futures[future]
            record, classify_result, error = future.result()
            output_filename = record["output_filename"]
            
            if classify_result is not None:
                # æˆåŠŸ - å†™å…¥ç»“æœæ–‡ä»¶
                result_record = record.copy()
                result_record["classify_result"] = classify_result
                append_to_jsonl(OUTPUT_JSONL, result_record)
                success_count += 1
            else:
                # å¤±è´¥ - å†™å…¥å¤±è´¥æ–‡ä»¶
                failed_record = record.copy()
                failed_record["error"] = error
                append_to_jsonl(FAILED_JSONL, failed_record)
                fail_count += 1
            
            # æ˜¾ç¤ºè¿›åº¦
            completed = success_count + fail_count
            elapsed = time.time() - start_time
            rate = completed / elapsed if elapsed > 0 else 0
            eta = (total - completed) / rate if rate > 0 else 0
            
            # æ¯å¤„ç†ä¸€å®šæ•°é‡æ˜¾ç¤ºè¿›åº¦
            if completed % 10 == 0 or completed == total:
                print(f"\râ³ è¿›åº¦: {completed}/{total} ({100*completed/total:.1f}%) | "
                      f"âœ“ {success_count} âœ— {fail_count} | "
                      f"é€Ÿåº¦: {rate:.1f}/s | ETA: {eta:.0f}s", end="", flush=True)
    
    print()  # æ¢è¡Œ
    
    elapsed_total = time.time() - start_time
    print("\n" + "=" * 60)
    print(f"ğŸ“Š å¤„ç†å®Œæˆ!")
    print(f"   âœ“ æˆåŠŸ: {success_count}")
    print(f"   âœ— å¤±è´¥: {fail_count}")
    print(f"   â±ï¸ è€—æ—¶: {elapsed_total:.1f}s")
    print(f"   ğŸ“ˆ é€Ÿåº¦: {(success_count + fail_count) / elapsed_total:.1f} å¼ /ç§’")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ Gemini æ‰¹é‡åˆ†ç±»")
    print("=" * 60)
    
    # æ£€æŸ¥ API KEY
    if not LUMOS_API:
        print("âŒ è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® LUMOS_API")
        sys.exit(1)
    
    print(f"âœ“ API å·²é…ç½®")
    print(f"âœ“ å¹¶å‘æ•°: {MAX_WORKERS}")
    
    # åŠ è½½æ•°æ®
    print("\nğŸ“‚ åŠ è½½æ•°æ®...")
    processed_filenames = load_processed_filenames()
    print(f"   å·²å¤„ç†: {len(processed_filenames)} æ¡")
    
    all_records = load_input_records()
    print(f"   æ€»è®°å½•: {len(all_records)} æ¡")
    
    # è¿‡æ»¤å‡ºå¾…å¤„ç†çš„è®°å½•
    pending_records = [
        r for r in all_records
        if r.get("output_filename") not in processed_filenames
    ]
    print(f"   å¾…å¤„ç†: {len(pending_records)} æ¡")
    
    if not pending_records:
        print("\nâœ… æ‰€æœ‰å›¾ç‰‡éƒ½å·²å¤„ç†å®Œæˆ!")
        return
    
    # ç¡®è®¤å¼€å§‹
    print(f"\nâš ï¸ å³å°†å¤„ç† {len(pending_records)} æ¡è®°å½•")
    print("   æŒ‰ Ctrl+C å¯éšæ—¶ä¸­æ–­ï¼ˆå·²å¤„ç†çš„ç»“æœä¼šä¿å­˜ï¼‰")
    
    try:
        # å¼€å§‹æ‰¹é‡å¤„ç†
        run_batch_classify(pending_records, max_workers=MAX_WORKERS)
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­ï¼Œå·²å¤„ç†çš„ç»“æœå·²ä¿å­˜")
    
    print("\n" + "=" * 60)
    print("âœ… å®Œæˆ!")
    print(f"ğŸ“„ ç»“æœæ–‡ä»¶: {OUTPUT_JSONL}")
    if FAILED_JSONL.exists():
        print(f"ğŸ“„ å¤±è´¥è®°å½•: {FAILED_JSONL}")
    print("=" * 60)


if __name__ == "__main__":
    main()
